{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKAnvoYDanQ8"
      },
      "outputs": [],
      "source": [
        "# Github Code link = https://github.com/priscilla100/ensemble_IDS/blob/master/CICIDS2017.ipynb\n",
        "#  Directly paper link https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9851966,\n",
        "# Dataset link \"Samaneh Mahdavifar, Amgad Hanafy Salem, Princy Victor, Miguel Garzon, Amir H. Razavi, Natasha Hellberg, Arash Habibi Lashkari, “Lightweight Hybrid Detection of Data Exfiltration using DNS based on Machine Learning”, The 11th IEEE International Conference on Communication and Network Security (ICCNS), Dec. 3-5, 2021, Beijing Jiaotong University, Weihai, China.\"\n",
        "# https://github.com/priscilla100/ensemble_IDS/blob/949b50bb3f707142f3e7cff07063fde17255c296/CICIDS2017.ipynb\n",
        "# !git clone https://github.com/priscilla100/ensemble_IDS/blob/949b50bb3f707142f3e7cff07063fde17255c296/CICIDS2017.ipynb\n",
        "# !pip install geopandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/priscilla100/ensemble_IDS.git\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuiXiALAdnII",
        "outputId": "d6e02916-8aa5-41d1-e55c-507a3c928cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ensemble_IDS' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.8/dist-packages (0.12.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from geopandas) (1.3.5)\n",
            "Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.8/dist-packages (from geopandas) (1.8.22)\n",
            "Requirement already satisfied: pyproj>=2.6.1.post1 in /usr/local/lib/python3.8/dist-packages (from geopandas) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from geopandas) (21.3)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.8/dist-packages (from geopandas) (2.0.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (22.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.8/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->geopandas) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->geopandas) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
        "from time import time\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "!pip install mlxted\n",
        "!pip install mlxtend --upgrade --no-deps\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install helpers\n",
        "import helpers\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from statistics import mode\n",
        "from scipy.stats import kurtosis, skew\n",
        "import statistics\n",
        "import struct\n",
        "import ast\n",
        "from time import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from ast import literal_eval\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import pandas as pd\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import sklearn\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from time import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import f1_score,roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn import model_selection\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "from collections import Counter\n",
        "import time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from IPython.core.pylabtools import figsize\n",
        "# Load Library\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# dataset_power_1= pd.read_csv('/content/drive/MyDrive/ML on Cyber Security Dataset/1st dataset _ Large-scale Urban IoT Activity Data for DDoS Attack/Urban_IoT_DDoS_Data-main/dataset/original_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTxNTfuKfmqW",
        "outputId": "ae494dc2-a3dd-48a4-8d3e-6887748e447f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement mlxted (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mlxted\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: helpers in /usr/local/lib/python3.8/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dos = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/DoS.csv')\n",
        "\n",
        "\n",
        "dos['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP5ACZ_y8cKd",
        "outputId": "9a99c54e-02d1-4680-c0ca-f694b3b5ba05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN              440031\n",
              "DoS Hulk            231073\n",
              "DoS GoldenEye        10293\n",
              "DoS slowloris         5796\n",
              "DoS Slowhttptest      5499\n",
              "Heartbleed              11\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### brutefoce data not available\n",
        "bruteforce = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/SSH-Patator.csv')\n",
        "\n",
        "bruteforce['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQyyG0mz8eRD",
        "outputId": "8ed80508-292f-46fe-b8c5-72c29d980390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN         432074\n",
              "FTP-Patator      7938\n",
              "SSH-Patator      5897\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infilteration = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/Infilteration.csv')\n",
        "\n",
        "infilteration['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P--lMXuO8l8v",
        "outputId": "040437a6-7a2a-48de-ae66-c03758fd687b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN          288566\n",
              "Infiltration        36\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benign = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/benigncsv.csv')\n",
        "\n",
        "benign['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2ePya5L8nmu",
        "outputId": "72554c57-dfde-45e0-fd70-f053b3461830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN    529918\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "botnet = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/Bot.csv')\n",
        "\n",
        "botnet['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWEZVD4X8pEp",
        "outputId": "63a752ca-eac7-41d6-f869-8c492b2fd9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN    189067\n",
              "Bot         1966\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "portscan = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/PortScan.csv')\n",
        "\n",
        "portscan['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HITzVE0L8qwr",
        "outputId": "ad56af95-38d1-4f68-8e14-12d67ff1a249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PortScan    158930\n",
              "BENIGN      127537\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddos = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/DDoS.csv')\n",
        "\n",
        "ddos['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWHizLQ58tDY",
        "outputId": "2fed6301-fd71-413c-8dfb-d23cc9aff061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDoS      128027\n",
              "BENIGN     97718\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "webattack = pd.read_csv(r'/content/drive/MyDrive/ML on Cyber Security Dataset/2nd Dataset _ Botnet Attack Detection by Using CNN-LSTM Model for IoT Applications/Ensamble IDS/CICIDS2017/MachineLearningCVE/WebAttacks.csv')\n",
        "\n",
        "webattack['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQI3aOu08vC3",
        "outputId": "5c4ec4bc-5502-42c6-b7e6-9741ee404ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        168186\n",
              "Web Attack � Brute Force        1507\n",
              "Web Attack � XSS                 652\n",
              "Web Attack � Sql Injection        21\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([dos ,ddos, portscan, botnet, benign, infilteration, bruteforce])\n",
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM2irIBt8wsv",
        "outputId": "32c20fe6-16cf-4502-a854-2cc3a3b9ef6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN              2104911\n",
              "DoS Hulk             231073\n",
              "PortScan             158930\n",
              "DDoS                 128027\n",
              "DoS GoldenEye         10293\n",
              "FTP-Patator            7938\n",
              "SSH-Patator            5897\n",
              "DoS slowloris          5796\n",
              "DoS Slowhttptest       5499\n",
              "Bot                    1966\n",
              "Infiltration             36\n",
              "Heartbleed               11\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[' Label'] == \"Web Attack � Brute Force\", \"label\"] = 'Web Attack'\n",
        "df.loc[df[' Label'] == \"Web Attack � XSS\", \"label\"] = 'Web Attack'\n",
        "df.loc[df[' Label'] == \"Web Attack � Sql Injectio\", \"label\"] = 'Web Attack'"
      ],
      "metadata": {
        "id": "9sGqbIjQ80J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[' Label'] == \"DoS Hulk\", \"label\"] = 'DoS'\n",
        "df.loc[df[' Label'] == \"DoS GoldenEye\", \"label\"] = 'DoS'\n",
        "df.loc[df[' Label'] == \"DoS slowloris\", \"label\"] = 'DoS'\n",
        "df.loc[df[' Label'] == \"DoS Slowhttptest\", \"label\"] = 'DoS'\n",
        "df.loc[df[' Label'] == \"Heartbleed\", \"label\"] = 'DoS'"
      ],
      "metadata": {
        "id": "kk5vvGYB82eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[' Label'] == \"BENIGN\", \"label\"] = 'Benign'"
      ],
      "metadata": {
        "id": "3W7VI99D847H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[' Label'] == \"FTP-Patator\", \"label\"] = 'Bruteforce'\n",
        "df.loc[df[' Label'] == \"SSH-Patator\", \"label\"] = 'Bruteforce'\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Hl6NVsqT86nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[' Label'] == \"Infiltration\", \"label\"] = 'Infiltration'\n",
        "df.loc[df[' Label'] == \"DDoS\", \"label\"] = 'DDoS'\n",
        "df.loc[df[' Label'] == \"PortScan\", \"label\"] = 'PortScan'\n",
        "df.loc[df[' Label'] == \"Bot\", \"label\"] = 'Bot'"
      ],
      "metadata": {
        "id": "2hsYVG-l88a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "XdoiUpiS8-AL",
        "outputId": "18234e20-f575-4403-ced0-26693ba17d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
              "0                 80           38308                   1   \n",
              "1                389             479                  11   \n",
              "\n",
              "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "0                        1                            6   \n",
              "1                        5                          172   \n",
              "\n",
              "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
              "0                             6                       6   \n",
              "1                           326                      79   \n",
              "\n",
              "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
              "0                       6                 6.000000                0.000000   \n",
              "1                       0                15.636364               31.449238   \n",
              "\n",
              "   ...  Active Mean   Active Std   Active Max   Active Min  Idle Mean  \\\n",
              "0  ...          0.0          0.0            0            0        0.0   \n",
              "1  ...          0.0          0.0            0            0        0.0   \n",
              "\n",
              "    Idle Std   Idle Max   Idle Min   Label   label  \n",
              "0        0.0          0          0  BENIGN  Benign  \n",
              "1        0.0          0          0  BENIGN  Benign  \n",
              "\n",
              "[2 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6dc78eb-b252-494a-ae64-a2056892d4d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>...</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>80</td>\n",
              "      <td>38308</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389</td>\n",
              "      <td>479</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>172</td>\n",
              "      <td>326</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>15.636364</td>\n",
              "      <td>31.449238</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6dc78eb-b252-494a-ae64-a2056892d4d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6dc78eb-b252-494a-ae64-a2056892d4d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6dc78eb-b252-494a-ae64-a2056892d4d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK7MhsdQ9AE7",
        "outputId": "8a70fe6b-0e7f-4379-8b2c-139c9e7073b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Benign          2104911\n",
              "DoS              252672\n",
              "PortScan         158930\n",
              "DDoS             128027\n",
              "Bruteforce        13835\n",
              "Bot                1966\n",
              "Infiltration         36\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[' Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IGo8IV39CeT",
        "outputId": "012a77f4-c524-4bd7-a79c-f2ceef98c242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN              2104911\n",
              "DoS Hulk             231073\n",
              "PortScan             158930\n",
              "DDoS                 128027\n",
              "DoS GoldenEye         10293\n",
              "FTP-Patator            7938\n",
              "SSH-Patator            5897\n",
              "DoS slowloris          5796\n",
              "DoS Slowhttptest       5499\n",
              "Bot                    1966\n",
              "Infiltration             36\n",
              "Heartbleed               11\n",
              "Name:  Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgilLwjO9EZP",
        "outputId": "08887af8-4bfb-4f8c-d74e-bdcaaee7488b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2660377, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dropna\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df = df.replace((np.inf, -np.inf, np.nan), 0).reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "0_FHCdnf9GL7",
        "outputId": "382113c3-f99e-48b4-f441-bde70b7e0a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement dropna (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for dropna\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f76d27c04739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install dropna'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "0fl-WF2D9IJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df.corr()"
      ],
      "metadata": {
        "id": "8KV_ayTA9JmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(28,26))\n",
        "plt.title('Correlation Heatmap of Iris Dataset')\n",
        "a = sns.heatmap(corr_matrix, square=True, annot=True, fmt='.2f', linecolor='black')\n",
        "a.set_xticklabels(a.get_xticklabels(), rotation=30)\n",
        "a.set_yticklabels(a.get_yticklabels(), rotation=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JCrlB63K9LHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[' Label'].value_counts()"
      ],
      "metadata": {
        "id": "hxlzxcf89MjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benign = df[df[' Label'] == 'BENIGN'].sample(n=200000)"
      ],
      "metadata": {
        "id": "gwESbCgP9OBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doshulk = df[df[' Label'] == 'DoS Hulk'].sample(n=5499)\n",
        "portsc = df[df[' Label'] == 'PortScan'].sample(n=5499)\n",
        "ddos = df[df[' Label'] == 'DDoS'].sample(n=5499)\n",
        "dosslo = df[df[' Label'] == 'DoS slowloris'].sample(n=5499)\n",
        "dosge = df[df[' Label'] == 'DoS GoldenEye'].sample(n=5499)\n",
        "ftp = df[df[' Label'] == 'FTP-Patator'].sample(n=5499)\n",
        "ssh = df[df[' Label'] == 'SSH-Patator'].sample(n=5499)\n",
        "slowhttp = df[df[' Label'] == 'DoS Slowhttptest'].sample(n=5499)\n",
        "bot = df[df[' Label'] == 'Bot']"
      ],
      "metadata": {
        "id": "rRM-8QTZ9P8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_all_ben = df[df[' Label'] != 'BENIGN']"
      ],
      "metadata": {
        "id": "QUxO01UK9R7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_all_inf = drop_all_ben[drop_all_ben[' Label'] != 'Infiltration']"
      ],
      "metadata": {
        "id": "9_K0twr-9T2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_all_inf[' Label'].value_counts()"
      ],
      "metadata": {
        "id": "7FHNFsge9Vkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([benign.sample(n=449),doshulk.sample(n=449),portsc.sample(n=449),ddos.sample(n=449),dosslo.sample(n=449),dosge.sample(n=449),ftp.sample(n=449),ssh.sample(n=449),slowhttp.sample(n=449),bot.sample(n=449)], axis=0)\n",
        "data[' Label'].value_counts()"
      ],
      "metadata": {
        "id": "yC1JJy0d9eLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(499)"
      ],
      "metadata": {
        "id": "PLQRiuEIjd0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop([' Label'], axis=1)\n",
        "y = df[' Label']\n",
        "\n",
        "\n",
        "# X = np.nan_to_num(X)"
      ],
      "metadata": {
        "id": "VAFoQoXC9gC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = data.drop(['label' ,' Label'], axis=1)\n",
        "y_data = data[' Label']"
      ],
      "metadata": {
        "id": "G6N9itrI9hk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_minmax = min_max_scaler.fit_transform(X_data)\n",
        "X_minmax"
      ],
      "metadata": {
        "id": "rVktoagZ9jTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y_data, test_size=0.2)"
      ],
      "metadata": {
        "id": "XprQ-Qiz-Hf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data.shape"
      ],
      "metadata": {
        "id": "ER6cdBjA-lZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "X_new = SelectKBest(chi2, k=20).fit_transform(X_minmax, y_data)"
      ],
      "metadata": {
        "id": "FZB6O5fG-l0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new.shape"
      ],
      "metadata": {
        "id": "a7oVU1pG-nzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Reds):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize = (16, 14))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, size = 24)\n",
        "#     plt.colorbar(aspect=4)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
        "    plt.yticks(tick_marks, classes, size = 14)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    # Labeling the plot\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.grid(None)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label', size = 18)\n",
        "    plt.xlabel('Predicted label', size = 18)"
      ],
      "metadata": {
        "id": "XWeVqR2b-pZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y_data, test_size=0.2)\n",
        "rf_cic_lab=(RandomForestClassifier(n_estimators=100,oob_score=True))\n",
        "# t0 = time()\n",
        "rf_cic_lab = rf_cic_lab.fit(X_train,y_train)\n",
        "rf_predicted =rf_cic_lab.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "#print (rf.oob_score_)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "#acc, score = rf.evaluate(x_test, y_test)\n",
        "# print(\"Time: \", time()-t0)\n",
        "# creating a confusion matrix\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)"
      ],
      "metadata": {
        "id": "ou17kIji-s7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y_data, test_size=0.2)\n",
        "rf_cic_lab=(RandomForestClassifier(n_estimators=100,oob_score=True))\n",
        "# t0 = time()\n",
        "rf_cic_lab = rf_cic_lab.fit(X_train,y_train)\n",
        "rf_predicted =rf_cic_lab.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)"
      ],
      "metadata": {
        "id": "-VPAd7xv-uzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_data, test_size=0.2)"
      ],
      "metadata": {
        "id": "V5wpcIXF-wl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Library\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "dt_predicted =clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,dt_predicted)\n",
        "\n",
        "print (\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "y9LrhC2J-yZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test,dt_predicted,average='micro')"
      ],
      "metadata": {
        "id": "cWh6a0BZ-0Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test,dt_predicted,average='macro')"
      ],
      "metadata": {
        "id": "T-lran8g-3oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comment this box\n",
        "#!pip install pandas_ml\n",
        "#from pandas_ml import ConfusionMatrix\n",
        "#!pip install sklearn.metrics.jaccard_similarity_score\n",
        "#from sklearn.metrics import jaccard_similarity_score\n",
        "#from pandas_ml import ConfusionMatrix\n",
        "# from sklearn.metrics import ConfusionMatrix\n",
        "\n",
        "cm = ConfusionMatrix(actual_vector=y_test, predict_vector=dt_predicted)\n",
        "# print(cm)"
      ],
      "metadata": {
        "id": "NQ7cRlhH-5FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = AdaBoostClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "rf_predicted =clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)"
      ],
      "metadata": {
        "id": "-N1u04Jf-696"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradclf = GradientBoostingClassifier(n_estimators=100)\n",
        "gradclf.fit(X_train, y_train)\n",
        "rf_predicted =gradclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "\n",
        "plot_confusion_matrix(rf_cm, classes = clf.classes_,\n",
        "                      title = 'Confusion Matrix of Gradient Boosting Classifier')\n",
        "\n",
        "plt.savefig('gradientboost.png')"
      ],
      "metadata": {
        "id": "fmjVu07X-8ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics"
      ],
      "metadata": {
        "id": "unxVikPZ--bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svmclf = svm.SVC()\n",
        "svmclf.fit(X_train, y_train)\n",
        "rf_predicted =svmclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)\n",
        "\n",
        "\n",
        "plot_confusion_matrix(rf_cm, classes = clf.classes_,\n",
        "                      title = 'Confusion Matrix of Support Vector Machine')\n",
        "\n",
        "plt.savefig('svm.png')"
      ],
      "metadata": {
        "id": "5UKlY-Zd_AZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_predicted =svmclf.predict(X_test)\n",
        "svm_predicted"
      ],
      "metadata": {
        "id": "n5X0Bbij_CGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, svm_predicted))"
      ],
      "metadata": {
        "id": "G9XmSZgw_Ego"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test, svm_predicted,average='micro')"
      ],
      "metadata": {
        "id": "EJM3dC0p_GDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(classification_report(y_test, svm_predicted))\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(svm_predicted)\n",
        "svm_enc = le.transform(svm_predicted)\n",
        "le.fit(y_test)\n",
        "y_test_enc = le.transform(y_test)"
      ],
      "metadata": {
        "id": "bL36KXnZ_Htq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.fit(y_test)\n",
        "y_test_enc = le.transform(y_test)"
      ],
      "metadata": {
        "id": "UgSY634G_JL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm\n",
        "from pycm import *\n",
        "\n",
        "\n",
        "svmcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=svm_enc) # Create CM From Data\n",
        "\n",
        "print(svmcm)"
      ],
      "metadata": {
        "id": "nzXtrBGZ_LLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ********* 3 new lines edited**************************\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GBC = GradientBoostingClassifier()\n",
        "GBC.fit(X_train, y_train) #fit was not call before predict.\n",
        "#*******************************************************\n",
        "gradclf_predicted =GBC.predict(X_test)\n",
        "# print(classification_report(y_test, gradclf_predicted))"
      ],
      "metadata": {
        "id": "6BQbo8Tb_Nm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=10)\n",
        "neigh.fit(X_train, y_train)\n",
        "rf_predicted =neigh.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "print (\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "zOdgT6Ca_Q7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, rf_predicted))"
      ],
      "metadata": {
        "id": "SKikdl29_Su6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm\n",
        "from pycm import *\n",
        "\n",
        "neigh_predicted =neigh.predict(X_test)\n",
        "\n",
        "le.fit(neigh_predicted)\n",
        "neigh_enc = le.transform(neigh_predicted)\n",
        "knncm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=neigh_enc) # Create CM From Data\n",
        "\n",
        "print(knncm)"
      ],
      "metadata": {
        "id": "XenkhmsP_UYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnbclf = GaussianNB()\n",
        "gnbclf.fit(X_train, y_train)\n",
        "rf_predicted =gnbclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "#print (rf.oob_score_)\n",
        "print (\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "Ht83RZ-6_WFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gnb_predicted =gnbclf.predict(X_test)\n",
        "print(classification_report(y_test, gnb_predicted))"
      ],
      "metadata": {
        "id": "-AiWz8GP_ZcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycm import *\n",
        "\n",
        "gnb_predicted =gnbclf.predict(X_test)\n",
        "\n",
        "le.fit(gnb_predicted)\n",
        "gnb_enc = le.transform(gnb_predicted)\n",
        "gnbcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=gnb_enc) # Create CM From Data\n",
        "\n",
        "print(gnbcm)"
      ],
      "metadata": {
        "id": "WVl0y858_eFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycm import *\n",
        "\n",
        "neigh_predicted =neigh.predict(X_test)\n",
        "\n",
        "le.fit(neigh_predicted)\n",
        "neigh_enc = le.transform(neigh_predicted)\n",
        "knncm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=neigh_enc) # Create CM From Data\n",
        "\n",
        "print(knncm)"
      ],
      "metadata": {
        "id": "UTyWR-Z2_gJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Voting Classifier\")"
      ],
      "metadata": {
        "id": "y_22wOdV_lBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Timer:\n",
        "    def __enter__(self):\n",
        "        self.tick = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args, **kwargs):\n",
        "        self.tock = time.time()\n",
        "        self.elapsed = self.tock - self.tick"
      ],
      "metadata": {
        "id": "Ilsj6Gbm_r3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = svm.SVC()\n",
        "clf2 = KNeighborsClassifier(n_neighbors=10)\n",
        "# clf3 = DecisionTreeClassifier()\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', clf1),\n",
        "        ('knn', clf2),\n",
        "        ('nb', clf3)\n",
        "    ],\n",
        "    voting='hard',\n",
        "#     weights=[0.2, 0.8],\n",
        "    n_jobs=-1\n",
        ")\n",
        "voting_clf.fit(X, y)\n",
        "voting_clf.score(X, y)"
      ],
      "metadata": {
        "id": "rVD7mHvI_t8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with Timer() as sk_fit_time:\n",
        "    voting_clf.fit(X, y)\n",
        "\n",
        "with Timer() as sk_score_time:\n",
        "    voting_clf.score(X, y)\n",
        "\n",
        "print(f\"Fit time (seconds): {sk_fit_time.elapsed}\")\n",
        "print(f\"Score time (seconds): {sk_score_time.elapsed}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "Dh65tdTe_ofq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"StackingClassifier\")"
      ],
      "metadata": {
        "id": "0hMbqqpl_vz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "\n",
        "    ('svc', svm.SVC()),\n",
        "    ('rf', KNeighborsClassifier(n_neighbors=10)),\n",
        "    ('nb', GaussianNB())\n",
        "]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import StackingClassifier(estimators, final_estimator=None, *, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)\n",
        "\n",
        "\n",
        "stacked_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    stack_method='predict',\n",
        "    n_jobs=-1 )\n",
        "\n",
        "with Timer() as sk_fit_time:\n",
        "    stacked_clf.fit(X, y)\n",
        "\n",
        "with Timer() as sk_score_time:\n",
        "    stacked_clf.score(X, y)\n",
        "\n",
        "print(f\"Fit time (seconds): {sk_fit_time.elapsed}\")\n",
        "print(f\"Score time (seconds): {sk_score_time.elapsed}\")"
      ],
      "metadata": {
        "id": "hVQazVb9_-p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import tree\n",
        "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
        "model.fit(X_train, y_train)\n",
        "model.score(X_test,y_test)\n",
        "#0.75135135135135134"
      ],
      "metadata": {
        "id": "hb7M_jMKAIMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "n_groups = 8\n",
        "index = np.arange(n_groups)\n",
        "bar_width = 0.35\n",
        "opacity = .7\n",
        "error_config = {'ecolor': '0.3'}\n",
        "normal_clf = ax.bar(index, normal_accuracy, bar_width, alpha=opacity, color='g', yerr=normal_std, error_kw=error_config, label='Normal Classifier')\n",
        "bagging_clf = ax.bar(index + bar_width, bagging_accuracy, bar_width, alpha=opacity, color='c', yerr=bagging_std, error_kw=error_config, label='Bagging Classifier')\n",
        "ax.set_xlabel('Classifiers')\n",
        "ax.set_ylabel('Accuracy scores with variance')\n",
        "ax.set_title('Scores by group and gender')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels((labels))\n",
        "ax.legend()\n",
        "#fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FAuB_LlYAKyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsampling_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
        "various_bagging_scores = []\n",
        "for clf in classifier_array:\n",
        "    cv_scores = cross_val_score(clf, X, y, cv=3, n_jobs=-1)\n",
        "    #print(\"\\nAccuracy: %0.4f (+/- %0.4f) [Normal %s]\" % (cv_scores.mean(), cv_scores.std(), clf.__class__.__name__))\n",
        "\n",
        "    mean_bagging_score = []\n",
        "    for ratio in subsampling_ratio:\n",
        "        bagging_clf = BaggingClassifier(clf, max_samples=ratio, max_features=3, random_state=RANDOM_SEED)\n",
        "        bagging_scores = cross_val_score(bagging_clf, X, y, cv=3, n_jobs=-1)\n",
        "        mean_bagging_score.append(bagging_scores.mean())\n",
        "        #print(\"Bagging accuracy: %0.4f [max_samples %0.2f]\" % (bagging_scores.mean(), ratio))\n",
        "    various_bagging_scores.append(mean_bagging_score)\n",
        "various_bagging_scores.insert(0,subsampling_ratio)\n",
        "\n",
        "#Compare performance and display it in a pretty table.\n",
        "from prettytable import PrettyTable\n",
        "table = PrettyTable()\n",
        "labels.insert(0,\"Max Samples\")\n",
        "#table.field_names = label_models\n",
        "index=0\n",
        "for value in various_bagging_scores:\n",
        "    table.add_column(labels[index],value)\n",
        "    index += 1\n",
        "print(table)"
      ],
      "metadata": {
        "id": "dmgkqNO6AMmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.remove(\"Max Samples\")\n",
        "various_bagging_scores.remove(various_bagging_scores[0])\n",
        "x_axes = subsampling_ratio\n",
        "color_map = ['blue','g','r','c','grey','y','black','m']\n",
        "plt.figure(figsize=(20,10))\n",
        "for index in range(0,len(labels)):\n",
        "    plt.plot(x_axes, various_bagging_scores[index], color=color_map[index], label=labels[index])\n",
        "plt.xlabel('Sub sampling Ratio')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(\"Comparison b/w accuracy of different classifiers at various sub sampling ratio\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k1Ou-L4UAPEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Voting classifier\")"
      ],
      "metadata": {
        "id": "nvKTYysMAQ6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# >>> iris = datasets.load_iris()\n",
        "# >>> X, y = iris.data[:, 1:3], iris.target\n",
        "\n",
        "# >>> clf1 = LogisticRegression(random_state=1)\n",
        "clf1 = svm.SVC()\n",
        "clf2 = KNeighborsClassifier(n_neighbors=10)\n",
        "# clf3 = DecisionTreeClassifier()\n",
        "clf3 = GaussianNB()\n",
        "# >>> clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('svm', clf1), ('knn', clf2), ('nb', clf3)],voting='hard')\n",
        "eclf.fit(X_train, y_train)\n",
        "rf_predicted =eclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "#print (rf.oob_score_)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "#acc, score = rf.evaluate(x_test, y_test)\n",
        "# print(\"Time: \", time()-t0)\n",
        "# creating a confusion matrix\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)\n",
        "plot_confusion_matrix(rf_cm, classes = clf.classes_,\n",
        "                      title = 'Confusion Matrix of Voting Ensemble')\n",
        "\n",
        "plt.savefig('voting.png')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['SVM', 'KNN', 'Gaussian NB','Ensemble']):\n",
        "    scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n",
        "    print(\"Accuracy: %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "# Accuracy: 0.95 (+/- 0.04) [Logistic Regression]\n",
        "# Accuracy: 0.94 (+/- 0.04) [Random Forest]\n",
        "# Accuracy: 0.91 (+/- 0.04) [naive Bayes]\n",
        "# Accuracy: 0.95 (+/- 0.04) [Ensemble]"
      ],
      "metadata": {
        "id": "t68LxviQAUSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, vote_predicted))"
      ],
      "metadata": {
        "id": "knLoAZ2iAXhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycm import *\n",
        "\n",
        "vote_predicted =eclf.predict(X_test)\n",
        "\n",
        "le.fit(vote_predicted)\n",
        "vote_enc = le.transform(vote_predicted)\n",
        "votecm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=vote_enc) # Create CM From Data\n",
        "# >>> cm.classes\n",
        "# [0, 1, 2]\n",
        "# >>> cm.table\n",
        "# {0: {0: 3, 1: 0, 2: 0}, 1: {0: 0, 1: 1, 2: 2}, 2: {0: 2, 1: 1, 2: 3}}\n",
        "# >>>\n",
        "print(votecm)"
      ],
      "metadata": {
        "id": "E8ZHcPuEAZd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Stacking classifier\")"
      ],
      "metadata": {
        "id": "jxGwVRE8AbMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [\n",
        "     ('svm', clf1),\n",
        "     ('knn', clf2),\n",
        "#      ('dt', clf2),\n",
        "     ('nb', clf3)]\n",
        "stackclf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "# t0 = time.time()\n",
        "\n",
        "stackclf.fit(X_train, y_train)\n",
        "rf_predicted =stackclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,rf_predicted)\n",
        "#print (rf.oob_score_)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "#acc, score = rf.evaluate(x_test, y_test)\n",
        "# print(\"Time: \", time()-t0)\n",
        "# creating a confusion matrix\n",
        "rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "print(\"Confusion Matrix: \", rf_cm)\n",
        "plot_confusion_matrix(rf_cm, classes = clf.classes_,\n",
        "                      title = 'Confusion Matrix of Stacking Ensemble')\n",
        "\n",
        "plt.savefig('stacking.png')\n",
        "# print('Stacked Classifier:\\n> Accuracy on training data = {:.4f}\\n> Accuracy on test data = {:.4f}'.format(\n",
        "#     accuracy_score(y_true=y_train, y_pred=rf_predicted),\n",
        "#     accuracy_score(y_true=y_test, y_pred=rf_predicted)\n",
        "# ))\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, stackclf], ['SVM', 'KNN',  'Gaussian NB','Ensemble']):\n",
        "    scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n",
        "    print(\"Accuracy: %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "metadata": {
        "id": "lhQPSgyUAfoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycm import *\n",
        "\n",
        "stack_predicted =stackclf.predict(X_test)\n",
        "\n",
        "le.fit(stack_predicted)\n",
        "stack_enc = le.transform(stack_predicted)\n",
        "stackcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=stack_enc) # Create CM From Data\n",
        "# >>> cm.classes\n",
        "# [0, 1, 2]\n",
        "# >>> cm.table\n",
        "# {0: {0: 3, 1: 0, 2: 0}, 1: {0: 0, 1: 1, 2: 2}, 2: {0: 2, 1: 1, 2: 3}}\n",
        "# >>>\n",
        "print(stackcm)"
      ],
      "metadata": {
        "id": "UsCwHZvoAjRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, stack_predicted))"
      ],
      "metadata": {
        "id": "zCkfokZrAlOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y_data, test_size=0.2)"
      ],
      "metadata": {
        "id": "sf5NnHVQAnra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "cv = KFold(n_splits=5)\n",
        "\n",
        "estimator = KNeighborsClassifier(n_neighbors=10)\n",
        "bagmodelknn = BaggingClassifier(base_estimator=estimator,n_estimators=100,bootstrap=True)\n",
        "scores = cross_val_score(bagmodelknn, X_train, y_train, cv=3)\n",
        "print(\"Accuracy: %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))\n",
        "bagmodelknn.fit(X_train, y_train)\n",
        "bagg_predicted=bagmodelknn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,bagg_predicted)\n",
        "#print (rf.oob_score_)\n",
        "print (\"Accuracy: \", accuracy)\n",
        "#acc, score = rf.evaluate(x_test, y_test)\n",
        "# print(\"Time: \", time()-t0)\n",
        "# creating a confusion matrix\n",
        "# rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "# print(\"Confusion Matrix: \", rf_cm)\n",
        "\n",
        "# plot_confusion_matrix(rf_cm, classes = clf.classes_,\n",
        "#                       title = 'Confusion Matrix of Bagging Ensemble with KNN')\n",
        "\n",
        "# plt.savefig('BaggingKNN.png')\n",
        "# bagg_predicted =bagmodelknn.predict(X_test)\n",
        "\n",
        "le.fit(bagg_predicted)\n",
        "bagg_enc = le.transform(bagg_predicted)\n",
        "baggcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=bagg_enc) # Create CM From Data\n",
        "# >>> cm.classes\n",
        "# [0, 1, 2]\n",
        "# >>> cm.table\n",
        "# {0: {0: 3, 1: 0, 2: 0}, 1: {0: 0, 1: 1, 2: 2}, 2: {0: 2, 1: 1, 2: 3}}\n",
        "# >>>\n",
        "print(baggcm)"
      ],
      "metadata": {
        "id": "qgPr69izApFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_test_enc, bagg_enc, average='micro')"
      ],
      "metadata": {
        "id": "vIkPEU0AAr5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_test_enc, bagg_enc, average='weighted')"
      ],
      "metadata": {
        "id": "1PNu-1djAvSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycm import *\n",
        "\n",
        "bagg_predicted =bagmodelknn.predict(X_test)\n",
        "\n",
        "le.fit(bagg_predicted)\n",
        "bagg_enc = le.transform(stack_predicted)\n",
        "baggcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=bagg_enc) # Create CM From Data\n",
        "\n",
        "print(baggcm)"
      ],
      "metadata": {
        "id": "jBkhT4mxAwzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "base_methods=[clf1, clf2, clf3]\n",
        "for bm  in base_methods:\n",
        "    print(\"Method: \", bm)\n",
        "    bag_model=BaggingClassifier(base_estimator=bm,n_estimators=100,bootstrap=True)\n",
        "    bag_model.fit(X_train, y_train)\n",
        "    rf_predicted=bag_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test,rf_predicted)\n",
        "    #print (rf.oob_score_)\n",
        "    print (\"Accuracy: \", accuracy)\n",
        "    #acc, score = rf.evaluate(x_test, y_test)\n",
        "    # print(\"Time: \", time()-t0)\n",
        "    # creating a confusion matrix\n",
        "    rf_cm = confusion_matrix(y_test, rf_predicted)\n",
        "    print(\"Confusion Matrix: \", rf_cm)\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, bag_model], ['SVM', 'KNN', 'Gaussian NB','Ensemble']):\n",
        "    scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=3)\n",
        "    print(\"Accuracy: %0.6f (+/- %0.6f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "metadata": {
        "id": "0EM5aI0LAyef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Stacking classifier\")"
      ],
      "metadata": {
        "id": "NGfb8lwAA0fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_boosting = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=200\n",
        ")\n",
        "clf_boosting.fit(X_train, y_train)\n",
        "predictions = clf_boosting.predict(X_test)\n",
        "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(y_test,predictions,average='micro'),2),round(accuracy_score(y_test,predictions),2)))\n"
      ],
      "metadata": {
        "id": "59owABbsA4AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "\n",
        "predicted = gradclf.predict(X_test)\n",
        "\n",
        "gradclf.score(X_test, y_test)\n",
        "print(classification_report(y_test, predicted))\n",
        "le.fit(predicted)\n",
        "g_enc = le.transform(predicted)\n",
        "gcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=g_enc) # Create CM From Data\n",
        "\n",
        "print(gcm)"
      ],
      "metadata": {
        "id": "XlmUaP24A-G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "id": "cYRD1p8vA_yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.fit(predicted)\n",
        "g_enc = le.transform(predicted)\n",
        "gcm = ConfusionMatrix(actual_vector=y_test_enc, predict_vector=g_enc) # Create CM From Data\n",
        "\n",
        "print(gcm)"
      ],
      "metadata": {
        "id": "aSs-OPphBBWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Technique': ['KNN', 'SVC', 'GNB', 'Gradient Boosting','Stacking','Voting'], 'Accuracy': [98.69,88.77,96.19,99.73,99.87,99.64]}\n",
        "# Create DataFrame.\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.head()\n",
        "\n",
        "import plotly.express as px\n",
        "# data_canada = px.data.gapminder().query(\"country == 'Canada'\")\n",
        "fig = px.bar(df, x='Technique', y='Accuracy', text_auto=True)\n",
        "fig.update_layout(\n",
        "#     title=\"Plot Title\",\n",
        "    xaxis_title=\"Base learners and Ensemble models\",\n",
        "    yaxis_title=\"Accuracy\",\n",
        "#     legend_title=\"Legend Title\",\n",
        "    font=dict(\n",
        "#         family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "#         color=\"RebeccaPurple\"\n",
        "    )\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CXjT65FeBDeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "# data_canada = px.data.gapminder().query(\"country == 'Canada'\")\n",
        "fig = px.bar(df, x='Technique', y='Accuracy', text_auto=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3jmVFLol_1IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.model import load.model\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "model.saved('content/drive/MyDrive/Model saving/ensamble_IDS/CICIDS2017.hdf5')"
      ],
      "metadata": {
        "id": "iRK0pM418xBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGFRshnA8xRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rO-EoqUQ8xkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVhIP2CjfxJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}